{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q1.** You are working on a machine learning project where you have a dataset containing numerical and\n",
    "categorical features. You have identified that some of the features are highly correlated and there are\n",
    "missing values in some of the columns. You want to build a pipeline that automates the feature\n",
    "engineering process and handles the missing values.\n",
    "\n",
    "Design a pipeline that includes the following steps.\n",
    "\n",
    "Use an automated feature selection method to identify the important features in the dataset\n",
    "\n",
    "Create a numerical pipeline that includes the following steps\n",
    "\n",
    "Impute the missing values in the numerical columns using the mean of the column values\n",
    "\n",
    "Scale the numerical columns using standardisation\n",
    "\n",
    "Create a categorical pipeline that includes the following steps\n",
    "\n",
    "Impute the missing values in the categorical columns using the most frequent value of the column\n",
    "\n",
    "One-hot encode the categorical columns\n",
    "\n",
    "Combine the numerical and categorical pipelines using a ColumnTransformer\n",
    "\n",
    "Use a Random Forest Classifier to build the final model\n",
    "\n",
    "Evaluate the accuracy of the model on the test dataset\n",
    "\n",
    "**Note! Your solution should include code snippets for each step of the pipeline, and a brief explanation of\n",
    "each step. You should also provide an interpretation of the results and suggest possible improvements for\n",
    "the pipeline**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Load Titanic dataset using pandas\n",
    "titanic_data = pd.read_csv('https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv')\n",
    "\n",
    "titanic_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop non-numeric columns and target variable\n",
    "X = titanic_data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin', 'Survived'], axis=1)\n",
    "y = titanic_data['Survived']\n",
    "\n",
    "# Split dataset into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define numeric and categorical features\n",
    "numeric_features = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "categorical_features = X.select_dtypes(include=['object']).columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1:** Use an automated feature selection method to identify the important features in the dataset.\n",
    "\n",
    "**Automated Feature Selection:** We use a RandomForestClassifier to select important features automatically. This helps in reducing overfitting and improving model efficiency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Automated feature selection\n",
    "feature_selection = SelectFromModel(RandomForestClassifier())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2:** Create a numerical pipeline that includes imputing missing values using the mean of the column values and scaling the numerical columns using standardization.\n",
    "\n",
    "**Numerical Pipeline:** Missing values in numerical columns are imputed with the mean of the column values to maintain data integrity. Standardization is then applied to scale numerical features to a standard range, making them comparable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Numerical pipeline\n",
    "numeric_pipeline = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3:** Create a categorical pipeline that includes imputing missing values using the most frequent value of the column and one-hot encoding the categorical columns.\n",
    "\n",
    "**Categorical Pipeline:** Missing values in categorical columns are imputed with the most frequent value of the column to maintain data integrity. One-hot encoding is performed to convert categorical variables into a format suitable for machine learning algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Categorical pipeline\n",
    "categorical_pipeline = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 4:** Combine the numerical and categorical pipelines using a ColumnTransformer.\n",
    "\n",
    "**Column Transformer:** Numerical and categorical pipelines are combined using ColumnTransformer to apply appropriate preprocessing steps to different types of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Combine numerical and categorical pipelines\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_pipeline, numeric_features),\n",
    "        ('cat', categorical_pipeline, categorical_features)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 5:** Use a Random Forest Classifier to build the final model.\n",
    "\n",
    "**Random Forest Classifier:** We use a Random Forest Classifier as the final model. Random forests are robust, handle non-linearity well, and can handle large datasets with high dimensionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Final pipeline with preprocessing and classifier\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', RandomForestClassifier())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 6:** Evaluate the accuracy of the model on the test dataset.\n",
    "\n",
    "**Evaluation:** The accuracy of the model on the test dataset is evaluated. Accuracy gives us an idea of how well the model is performing in terms of correctly predicting the class labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8156424581005587\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Fit pipeline on training data\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Step 7: Predict on test data\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Step 8: Evaluate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code provided is a machine learning pipeline designed to classify whether passengers on the Titanic survived or not based on various features such as age, sex, ticket class, etc. \n",
    "\n",
    "The accuracy of the model is approximately 81.89%, which means that the model correctly predicts the survival outcomes for about 81.89% of the passengers in the test set.\n",
    "\n",
    "Interpreting this accuracy score, we can say that the model performs reasonably well in classifying whether passengers survived or not based on the given features. However, there is still room for improvement to achieve even higher accuracy.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Possible improvements could include further fine-tuning of the model hyperparameters, exploring additional feature engineering techniques, trying out different classification algorithms, and addressing any class imbalance issues if present in the dataset.\n",
    "\n",
    "Overall, achieving an accuracy of around 80% is a good starting point, but further refinement of the model could potentially enhance its predictive performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q2.** Build a pipeline that includes a random forest classifier and a logistic regression classifier, and then\n",
    "use a voting classifier to combine their predictions. Train the pipeline on the iris dataset and evaluate its\n",
    "accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Step 2: Load the Iris dataset\n",
    "iris_data = load_iris()\n",
    "X = iris_data.data\n",
    "y = iris_data.target\n",
    "\n",
    "# Step 3: Split the dataset into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 4: Create individual pipelines for Random Forest Classifier and Logistic Regression Classifier\n",
    "rf_pipeline = Pipeline(steps=[\n",
    "    ('random_forest', RandomForestClassifier())\n",
    "])\n",
    "\n",
    "lr_pipeline = Pipeline(steps=[\n",
    "    ('logistic_regression', LogisticRegression())\n",
    "])\n",
    "\n",
    "# Step 5: Combine the individual pipelines into a Voting Classifier\n",
    "voting_pipeline = VotingClassifier(estimators=[\n",
    "    ('rf', rf_pipeline),\n",
    "    ('lr', lr_pipeline)\n",
    "], voting='hard')\n",
    "\n",
    "# Step 6: Train the pipeline on the Iris dataset\n",
    "voting_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Step 7: Evaluate the accuracy of the pipeline\n",
    "y_pred = voting_pipeline.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
